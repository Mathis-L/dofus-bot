{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAhCov4i-Vn4"
      },
      "source": [
        "# Entra√Ænement d'un Mod√®le de Computer Vision YOLO Personnalis√© pour Dofus (Transfer Learning)\n",
        "## INTRODUCTION\n",
        "Bienvenue dans ce guide interactif ! L'objectif est de vous accompagner, √©tape par √©tape, dans l'entra√Ænement d'un mod√®le de d√©tection d'objets YOLO personnalis√©. Gr√¢ce √† ce mod√®le, vous pourrez reconna√Ætre automatiquement des ressources pour bucheron et paysan dans des images du jeu Dofus.\n",
        "\n",
        "**Les outils que nous allons utiliser :**\n",
        "1.  **Votre dataset Dofus annot√© :**\n",
        "    *   **Option A (Label Studio) :** Vous l'avez pr√©par√© avec soin en utilisant Label Studio.\n",
        "    *   **Option B (Roboflow) :** Vous pouvez utilis√© roboflow pour r√©cup√©rer mon dataset ou faire le votre.\n",
        "2.  **Ultralytics :** Une biblioth√®que Python puissante et conviviale pour entra√Æner les derni√®res g√©n√©rations de mod√®les YOLO.\n",
        "3.  **Google Colab :** Notre environnement de travail. Il nous offre un acc√®s gratuit √† des GPUs (processeurs graphiques), indispensables pour acc√©l√©rer l'entra√Ænement.\n",
        "\n",
        "**Ce que vous obtiendrez √† la fin :**\n",
        "-   Un mod√®le YOLO entra√Æn√© et performant (un fichier `.pt`).\n",
        "-   Un fichier ZIP (`dofus_AI.zip`) contenant votre mod√®le et les fichiers de configuration, pr√™t √† √™tre t√©l√©charg√© et utilis√© dans vos propres projets.\n",
        "\n",
        "Suivez attentivement les √©tapes ci-dessous. Chaque bloc de code est ex√©cutable directement dans Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw8eDQMt2n1o"
      },
      "source": [
        "# √âTAPE 0 : V√âRIFIER LA DISPONIBILIT√â DU GPU NVIDIA\n",
        "Pour que l'entra√Ænement soit rapide, il est crucial d'utiliser un GPU.\n",
        "**Action :** Assurez-vous que Colab utilise bien un GPU.\n",
        "1.  Dans le menu Colab : \"Ex√©cution\" (ou \"Runtime\").\n",
        "2.  Cliquez sur \"Modifier le type d'ex√©cution\" (ou \"Change runtime type\").\n",
        "3.  Dans la section \"Acc√©l√©rateur mat√©riel\" (ou \"Hardware accelerator\"), s√©lectionnez \"GPU\" (g√©n√©ralement T4).\n",
        "4.  Sauvegardez.\n",
        "\n",
        "Ex√©cutez la commande ci-dessous pour confirmer que le GPU est bien d√©tect√© :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IUyVwFsU8LkS"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_OrtOJ_2tbZ"
      },
      "source": [
        "*(Vous devriez voir appara√Ætre des informations sur un GPU NVIDIA, comme Tesla T4, K80, etc.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**SI VOUS UTILISEZ UN DATASET EXPORT√â DE LABEL STUDIO, SUIVEZ L'√âTAPE 1 CI-DESSOUS.**   \n",
        "**SI VOUS UTILISEZ UN DATASET EXPORT√â DE ROBOFLOW, PASSEZ DIRECTEMENT √Ä L'√âTAPE 1 (ALTERNATIVE) CI-DESSOUS.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh53QKVF--Gz"
      },
      "source": [
        "## √âTAPE 1 : PR√âPARATION DE VOTRE DATASET DOFUS (EXPORT√â DE LABEL STUDIO)\n",
        "\n",
        "Cette √©tape est fondamentale : la qualit√© de votre mod√®le d√©pendra directement de la qualit√© de votre dataset.\n",
        "\n",
        "### 1.1 Rappels sur la pr√©paration de votre dataset avec Label Studio\n",
        "Pour cr√©er le dataset j'ai utilis√© Label Studio ([https://labelstud.io/](https://labelstud.io/)) qui permet d'annoter nos images Dofus. Pour la d√©tection d'objets avec YOLO, le processus consiste √† :\n",
        "1.  Dessiner des **bo√Ætes englobantes** (bounding boxes) autour des objets d'int√©r√™t, des ressources dans notre cas.\n",
        "2.  Assigner une **classe** (un nom) √† chaque bo√Æte (par exemple, \"Frene\", \"Ble\", \"Eau\").\n",
        "\n",
        "**Format d'exportation depuis Label Studio :**\n",
        "Lorsque vous exportez votre projet depuis Label Studio, il est imp√©ratif de choisir le format **\"YOLO\"**.\n",
        "Cet export g√©n√®re typiquement :\n",
        "-   Un dossier `images/` : Contient toutes vos images originales (ex: `.jpg`, `.png`).\n",
        "-   Un dossier `labels/` : Contient des fichiers `.txt` portant le m√™me nom que vos images. Chaque fichier `.txt` d√©crit les objets de l'image correspondante, avec une ligne par objet :\n",
        "    `<class_id> <x_center_norm> <y_center_norm> <width_norm> <height_norm>`\n",
        "    *   `<class_id>` : Un num√©ro identifiant la classe (commen√ßant √† 0).\n",
        "    *   Les autres valeurs sont les coordonn√©es normalis√©es (entre 0 et 1) du centre de la bo√Æte, sa largeur et sa hauteur, relatives √† la taille de l'image.\n",
        "-   Un fichier `classes.txt` : Liste tous les noms de vos classes, un par ligne. L'ordre est CRUCIAL car il d√©finit les `class_id` (la premi√®re ligne est la classe 0, la deuxi√®me la classe 1, etc.).\n",
        "\n",
        "**‚úÖ Action requise de votre part (pr√©paration du ZIP) :**\n",
        "1.  Exportez votre projet Label Studio au format YOLO.\n",
        "2.  Cr√©ez un fichier ZIP unique nomm√© `data.zip`.\n",
        "3.  **Important :** Ce `data.zip` DOIT contenir **√Ä SA RACINE** (pas dans un sous-dossier √† l'int√©rieur du ZIP) :\n",
        "    -   Le dossier `images/` (avec vos images).\n",
        "    -   Le dossier `labels/` (avec vos fichiers d'annotation `.txt`).\n",
        "    -   Le fichier `classes.txt` (listant vos classes).\n",
        "\n",
        "**Exemple de structure attendue √† l'int√©rieur de `data.zip` :**\n",
        "```\n",
        "data.zip/\n",
        "  ‚îú‚îÄ‚îÄ images/\n",
        "  ‚îÇ   ‚îú‚îÄ‚îÄ dofus_image1.jpg\n",
        "  ‚îÇ   ‚îú‚îÄ‚îÄ dofus_image2.png\n",
        "  ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "  ‚îú‚îÄ‚îÄ labels/\n",
        "  ‚îÇ   ‚îú‚îÄ‚îÄ dofus_image1.txt\n",
        "  ‚îÇ   ‚îú‚îÄ‚îÄ dofus_image2.txt\n",
        "  ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "  ‚îî‚îÄ‚îÄ classes.txt\n",
        "```\n",
        "**Exemple de contenu du fichier `classes.txt` pour Dofus :**\n",
        "```\n",
        "Frene\n",
        "Ble\n",
        "Eau\n",
        "...\n",
        "```\n",
        "*(Assurez-vous que les noms de classes sont exacts et dans l'ordre souhait√©.)*\n",
        "\n",
        "### 1.2 T√©l√©verser votre `data.zip` sur Colab\n",
        "\n",
        "Vous avez deux options pour importer votre `data.zip` dans l'environnement Colab.\n",
        "\n",
        "**OPTION A : T√©l√©chargement direct via l'interface Colab (pour les petits fichiers, < 100Mo)**\n",
        "1.  Dans la barre lat√©rale gauche de Colab, cliquez sur l'ic√¥ne \"Dossier\" üìÅ.\n",
        "2.  Cliquez sur l'ic√¥ne \"Importer dans l'espace de stockage de la session\" (üìÑ‚Üë).\n",
        "3.  S√©lectionnez votre fichier `data.zip` depuis votre ordinateur.\n",
        "4.  Attendez que le t√©l√©chargement soit complet (le fichier `data.zip` appara√Ætra dans la liste).\n",
        "\n",
        "**OPTION B : Copier depuis Google Drive (recommand√© pour les datasets plus volumineux)**\n",
        "1.  Uploadez votre `data.zip` sur votre Google Drive (par exemple, dans un dossier `MesProjetsIA/Dofus`).  (Par exemple dans mon cas j'ai cr√©√© un dossier dans mon Drive appel√© DOFUS_BOT o√π j'ai mis mon `data.zip`)\n",
        "2.  Ex√©cutez le code ci-dessous. Vous devrez autoriser Colab √† acc√©der √† votre Drive.\n",
        "3.  **‚ö†Ô∏è ATTENTION :** Modifiez la ligne `!cp /content/gdrive/MyDrive/DOFUS_BOT/data.zip ...` pour qu'elle corresponde au chemin exact de votre `data.zip` sur votre Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NZg5Ght_4e5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/MyDrive/DOFUS_BOT/data.zip /content/data.zip # Adaptez ce chemin !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtp7ZAEpAM-W"
      },
      "source": [
        "### 1.3 D√©compresser le dataset et organiser les donn√©es pour l'entra√Ænement\n",
        "Une fois `data.zip` upload√©, il devrait se trouver dans `/content/data.zip`.\n",
        "V√©rifions sa pr√©sence :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMZMcjvyAOAf"
      },
      "outputs": [],
      "source": [
        "!ls -lh /content/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KglttKlXAP-k"
      },
      "source": [
        "Maintenant, d√©compressons ce ZIP. Nous allons placer son contenu dans un dossier `/content/custom_data`.\n",
        "Ce dossier `custom_data` contiendra donc vos dossiers `images/`, `labels/` et votre fichier `classes.txt` (exactement la structure que vous aviez dans le ZIP)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nwlRhXtAWc5"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/data.zip -d /content/custom_data\n",
        "# V√©rifions le contenu de custom_data\n",
        "!ls /content/custom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uJlTtCv4Tq6"
      },
      "source": [
        "*(Vous devriez voir `images`, `labels`, et `classes.txt` list√©s.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggj5qdlvAZEX"
      },
      "source": [
        "Ultralytics (et les bonnes pratiques en Machine Learning) n√©cessite que les donn√©es soient s√©par√©es en au moins deux ensembles :\n",
        "-   **Ensemble d'entra√Ænement (train) :** Utilis√© pour apprendre au mod√®le.\n",
        "-   **Ensemble de validation (val) :** Utilis√© pour √©valuer la performance du mod√®le sur des donn√©es qu'il n'a jamais vues pendant l'entra√Ænement. Cela aide √† d√©tecter le sur-apprentissage (overfitting) et √† choisir le \"meilleur\" mod√®le.\n",
        "\n",
        "Le script Python ci-dessous va :\n",
        "1.  Prendre vos donn√©es depuis `/content/custom_data/`.\n",
        "2.  Cr√©er une nouvelle structure de dossiers dans `/content/data/` avec des sous-dossiers `train/images`, `train/labels`, `validation/images`, `validation/labels`.\n",
        "3.  R√©partir al√©atoirement vos images (et leurs labels correspondants) entre ces ensembles d'entra√Ænement et de validation. Nous utiliserons une r√©partition classique de 80% pour l'entra√Ænement et 20% pour la validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feQLe6FcAdlw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Configuration du split ---\n",
        "data_path_source = \"/content/custom_data\"  # Dossier source apr√®s d√©compression de data.zip\n",
        "output_data_root = \"/content/data\"         # Dossier de sortie pour les donn√©es organis√©es\n",
        "train_percentage_split = 0.8               # 80% pour l'entra√Ænement, 20% pour la validation\n",
        "\n",
        "print(f\"Source des donn√©es : {data_path_source}\")\n",
        "print(f\"Destination des donn√©es organis√©es : {output_data_root}\")\n",
        "print(f\"Pourcentage pour l'entra√Ænement : {train_percentage_split*100}%\\n\")\n",
        "\n",
        "# V√©rifier si le dossier source existe\n",
        "if not os.path.isdir(data_path_source):\n",
        "   print(f\"ERREUR : Le dossier source '{data_path_source}' est introuvable.\")\n",
        "   print(\"Veuillez v√©rifier que votre `data.zip` a √©t√© correctement d√©compress√© dans `custom_data`.\")\n",
        "   # Vous pouvez ajouter un `raise Exception(...)` ici si vous voulez arr√™ter le script\n",
        "else:\n",
        "    # D√©finir les chemins des sous-dossiers source\n",
        "    input_image_path_str = os.path.join(data_path_source, 'images')\n",
        "    input_label_path_str = os.path.join(data_path_source, 'labels')\n",
        "\n",
        "    # V√©rifier l'existence des dossiers images et labels source\n",
        "    if not os.path.isdir(input_image_path_str):\n",
        "        print(f\"ERREUR : Le dossier d'images source '{input_image_path_str}' est introuvable dans '{data_path_source}'.\")\n",
        "    if not os.path.isdir(input_label_path_str):\n",
        "        print(f\"ERREUR : Le dossier de labels source '{input_label_path_str}' est introuvable dans '{data_path_source}'.\")\n",
        "\n",
        "    # D√©finir les chemins des dossiers de destination\n",
        "    train_img_path_str = os.path.join(output_data_root, 'train/images')\n",
        "    train_txt_path_str = os.path.join(output_data_root, 'train/labels')\n",
        "    val_img_path_str = os.path.join(output_data_root, 'validation/images')\n",
        "    val_txt_path_str = os.path.join(output_data_root, 'validation/labels')\n",
        "\n",
        "    # Cr√©er les dossiers de destination s'ils n'existent pas\n",
        "    for dir_path_str in [train_img_path_str, train_txt_path_str, val_img_path_str, val_txt_path_str]:\n",
        "       if not os.path.exists(dir_path_str):\n",
        "          os.makedirs(dir_path_str)\n",
        "          print(f\"Dossier cr√©√© : {dir_path_str}\")\n",
        "\n",
        "    # Obtenir la liste de tous les fichiers images\n",
        "    # Utilisation de Path pour rglob qui cherche r√©cursivement (utile si vous avez des sous-dossiers dans images/)\n",
        "    # Si vos images sont toutes √† la racine de 'images/', os.listdir pourrait aussi fonctionner.\n",
        "    img_file_list = [p for p in Path(input_image_path_str).rglob('*') if p.is_file()]\n",
        "    # S'assurer que ce sont bien des fichiers et pas des dossiers cach√©s comme .DS_Store\n",
        "    img_file_list = [f for f in img_file_list if not f.name.startswith('.')]\n",
        "\n",
        "\n",
        "    if not img_file_list:\n",
        "        print(f\"ERREUR : Aucun fichier image trouv√© dans '{input_image_path_str}'.\")\n",
        "    else:\n",
        "        print(f\"\\nNombre total de fichiers images trouv√©s : {len(img_file_list)}\")\n",
        "\n",
        "        # M√©langer la liste des fichiers pour une s√©lection al√©atoire\n",
        "        random.shuffle(img_file_list)\n",
        "\n",
        "        # D√©terminer le nombre de fichiers pour chaque ensemble\n",
        "        file_num_total = len(img_file_list)\n",
        "        train_num = int(file_num_total * train_percentage_split)\n",
        "        val_num = file_num_total - train_num\n",
        "\n",
        "        print(f\"Nombre d'images pour l'entra√Ænement : {train_num}\")\n",
        "        print(f\"Nombre d'images pour la validation : {val_num}\\n\")\n",
        "\n",
        "        # R√©partir les fichiers\n",
        "        print(\"D√©but de la copie des fichiers d'entra√Ænement...\")\n",
        "        for i in range(train_num):\n",
        "            img_path_obj = img_file_list[i]\n",
        "            img_filename = img_path_obj.name\n",
        "            base_filename = img_path_obj.stem\n",
        "            label_filename = base_filename + '.txt'\n",
        "            label_path_source_obj = Path(input_label_path_str) / label_filename\n",
        "\n",
        "            # Copier l'image\n",
        "            shutil.copy(str(img_path_obj), os.path.join(train_img_path_str, img_filename))\n",
        "\n",
        "            # Copier le fichier label correspondant s'il existe\n",
        "            if label_path_source_obj.exists():\n",
        "                shutil.copy(str(label_path_source_obj), os.path.join(train_txt_path_str, label_filename))\n",
        "            # else:\n",
        "            #     print(f\"  INFO: Fichier label '{label_filename}' non trouv√© pour l'image d'entra√Ænement '{img_filename}'. (Peut √™tre une image de fond)\")\n",
        "\n",
        "        print(\"Fin de la copie des fichiers d'entra√Ænement.\")\n",
        "        print(\"D√©but de la copie des fichiers de validation...\")\n",
        "        for i in range(train_num, file_num_total): # Les images restantes vont √† la validation\n",
        "            img_path_obj = img_file_list[i]\n",
        "            img_filename = img_path_obj.name\n",
        "            base_filename = img_path_obj.stem\n",
        "            label_filename = base_filename + '.txt'\n",
        "            label_path_source_obj = Path(input_label_path_str) / label_filename\n",
        "\n",
        "            # Copier l'image\n",
        "            shutil.copy(str(img_path_obj), os.path.join(val_img_path_str, img_filename))\n",
        "\n",
        "            # Copier le fichier label correspondant s'il existe\n",
        "            if label_path_source_obj.exists():\n",
        "                shutil.copy(str(label_path_source_obj), os.path.join(val_txt_path_str, label_filename))\n",
        "            # else:\n",
        "            #     print(f\"  INFO: Fichier label '{label_filename}' non trouv√© pour l'image de validation '{img_filename}'. (Peut √™tre une image de fond)\")\n",
        "        print(\"Fin de la copie des fichiers de validation.\")\n",
        "        print(\"\\nR√©partition des donn√©es termin√©e !\")\n",
        "\n",
        "# V√©rifions la structure cr√©√©e dans /content/data (facultatif mais utile)\n",
        "print(\"\\nContenu de /content/data :\")\n",
        "!ls /content/data\n",
        "print(\"\\nContenu de /content/data/train/images (premiers fichiers) :\")\n",
        "!ls /content/data/train/images | head -n 5\n",
        "print(\"\\nContenu de /content/data/train/labels (premiers fichiers) :\")\n",
        "!ls /content/data/train/labels | head -n 5\n",
        "print(\"\\nContenu de /content/data/validation/images (premiers fichiers) :\")\n",
        "!ls /content/data/validation/images | head -n 5\n",
        "print(\"\\nContenu de /content/data/validation/labels (premiers fichiers) :\")\n",
        "!ls /content/data/validation/labels | head -n 5\n",
        "print(\"--- Fin de la v√©rification ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "YOLO a besoin d'un fichier de configuration, traditionnellement nomm√© `data.yaml`. Ce fichier est comme une \"carte d'identit√©\" de votre dataset pour le mod√®le. Il lui indique :\n",
        "-   O√π trouver les images d'entra√Ænement et de validation.\n",
        "-   Le nombre de classes d'objets √† d√©tecter.\n",
        "-   Les noms de ces classes.\n",
        "\n",
        "Nous allons g√©n√©rer ce fichier `data.yaml` automatiquement √† partir de votre fichier `classes.txt` (que vous avez fourni dans `data.zip` et qui se trouve maintenant dans `/content/custom_data/classes.txt`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGPdpnNMtsEf"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt_in_custom_data, output_data_yaml_path, root_data_dir_for_yaml):\n",
        "  \"\"\"\n",
        "  Cr√©e le fichier data.yaml n√©cessaire pour l'entra√Ænement YOLO.\n",
        "\n",
        "  Args:\n",
        "    path_to_classes_txt_in_custom_data (str): Chemin vers votre fichier classes.txt original (ex: /content/custom_data/classes.txt).\n",
        "    output_data_yaml_path (str): Chemin o√π le fichier data.yaml sera sauvegard√© (ex: /content/dofus_data.yaml).\n",
        "    root_data_dir_for_yaml (str): Chemin racine que YOLO utilisera pour trouver les dossiers train/val (ex: /content/data).\n",
        "  \"\"\"\n",
        "  if not os.path.exists(path_to_classes_txt_in_custom_data):\n",
        "    print(f\"ERREUR : Le fichier {path_to_classes_txt_in_custom_data} est introuvable !\")\n",
        "    print(\"Veuillez v√©rifier que votre `data.zip` contenait bien `classes.txt` et qu'il a √©t√© extrait correctement.\")\n",
        "    return\n",
        "\n",
        "  with open(path_to_classes_txt_in_custom_data, 'r') as f:\n",
        "    classes = [line.strip() for line in f if line.strip()] # Lire les classes, ignorer les lignes vides\n",
        "\n",
        "  if not classes:\n",
        "    print(f\"ERREUR : Aucune classe n'a √©t√© trouv√©e dans {path_to_classes_txt_in_custom_data}. Le fichier est-il vide ou mal format√© ?\")\n",
        "    return\n",
        "\n",
        "  number_of_classes = len(classes)\n",
        "  print(f\"Nombre de classes d√©tect√©es : {number_of_classes}\")\n",
        "  print(f\"Noms des classes : {classes}\")\n",
        "\n",
        "  data_config = {\n",
        "      'path': root_data_dir_for_yaml,  # Chemin absolu vers le dossier contenant train/ et validation/\n",
        "      'train': 'train/images',       # Chemin relatif √† 'path' pour les images d'entra√Ænement\n",
        "      'val': 'validation/images',    # Chemin relatif √† 'path' pour les images de validation\n",
        "      # 'test': Optional: chemin vers les images de test\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  with open(output_data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, sort_keys=False, indent=2)\n",
        "  print(f\"Fichier de configuration YAML cr√©√© avec succ√®s : {output_data_yaml_path}\")\n",
        "\n",
        "# D√©finition des chemins\n",
        "# Le fichier classes.txt original se trouve dans custom_data apr√®s d√©compression.\n",
        "path_to_original_classes_txt = '/content/custom_data/classes.txt'\n",
        "# Le dossier racine pour les donn√©es format√©es (train/val) est /content/data.\n",
        "data_root_for_yolo = '/content/data'\n",
        "# Nous allons cr√©er notre fichier de configuration data.yaml √† la racine de /content.\n",
        "path_to_output_yaml = '/content/dofus_data.yaml' # Nommez-le comme vous voulez\n",
        "\n",
        "create_data_yaml(path_to_original_classes_txt, path_to_output_yaml, data_root_for_yolo)\n",
        "\n",
        "# Affichons le contenu du fichier YAML cr√©√© pour v√©rification\n",
        "print('\\nContenu du fichier data.yaml g√©n√©r√© :\\n')\n",
        "!cat {path_to_output_yaml}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âTAPE 1 (ALTERNATIVE) : PR√âPARATION DE VOTRE DATASET DOFUS (EXPORT√â DE ROBOFLOW)\n",
        "\n",
        "Mon dataset est disponible sur roboflow pour le t√©l√©charger ([https://roboflow.com/](https://universe.roboflow.com/mathisl-qvljq/dofus-resource-detection/dataset/1))\n",
        "\n",
        "### 1.A Exporter votre dataset depuis Roboflow\n",
        "1.  Dans votre projet Roboflow, apr√®s avoir annot√© et g√©n√©r√© une version de votre dataset.\n",
        "2.  Cliquez sur \"Export Dataset\".\n",
        "3.  Choisissez le format **\"YOLOv11\"** . Ce format inclut typiquement :\n",
        "    *   Des dossiers `train/`, `valid/` (et parfois `test/`) contenant chacun des sous-dossiers `images/` et `labels/`.\n",
        "    *   Un fichier `data.yaml` d√©j√† configur√© pour votre dataset.\n",
        "4.  Choisissez l'option \"download zip to computer\". Vous obtiendrez un fichier ZIP (par exemple, `MonProjetDofus.zip` ou `Dofus-Resources-1.zip`).\n",
        "5.  Renommer le `data.zip`.\n",
        "\n",
        "### 1.B T√©l√©verser votre `data.zip` (export√© de Roboflow) sur Colab\n",
        "\n",
        "Comme pour l'option Label Studio, vous pouvez soit le t√©l√©charger directement, soit passer par Google Drive (recommand√©).\n",
        "\n",
        "1.  Uploadez le fichier ZIP t√©l√©charg√© de Roboflow sur votre Google Drive (par exemple, dans un dossier `MesProjetsIA/DOFUS_BOT`).\n",
        "2.  Ex√©cutez le code ci-dessous. Vous devrez autoriser Colab √† acc√©der √† votre Drive.\n",
        "3.  **‚ö†Ô∏è ATTENTION :**\n",
        "    * Renommer le ZIP en `data.zip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# MODIFIER CETTE LIGNE AVEC LE CHEMIN DE VOTRE FICHIER ZIP SUR GOOGLE DRIVE\n",
        "path_to_zip_on_drive = f\"/content/gdrive/MyDrive/DOFUS_BOT/data.zip\" # EXEMPLE: \"/content/gdrive/MyDrive/MesDatasets/Roboflow_Exports/data.zip\"\n",
        "# --- FIN DES MODIFICATIONS ---\n",
        "\n",
        "destination_zip_path_colab = \"/content/data.zip\"\n",
        "\n",
        "print(f\"Tentative de copie de {path_to_zip_on_drive} vers {destination_zip_path_colab}\")\n",
        "!cp \"{path_to_roboflow_zip_on_drive}\" \"{destination_zip_path_colab}\"\n",
        "\n",
        "# V√©rifions sa pr√©sence :\n",
        "print(\"\\nContenu de /content apr√®s la copie :\")\n",
        "!ls -lh /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.C D√©compresser le dataset Roboflow\n",
        "Le ZIP de Roboflow contient d√©j√† la structure `train/`, `valid/` et le fichier data.yaml. Nous allons le d√©compresser dans un dossier sp√©cifique, `/content/data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip -q /content/data.zip -d /content/data\n",
        "# V√©rifions le contenu de custom_data\n",
        "!ls /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGF1xvgU4y7P"
      },
      "source": [
        "*(Vous devriez voir `train/`, `valid/`, `test/` et `data.yaml` list√©s.)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7cwEmGsuS5Z"
      },
      "source": [
        "## √âTAPE 2 : ENTRA√éNER LE MOD√àLE YOLO\n",
        "C'est le moment cl√© ! Nous allons lancer l'entra√Ænement.\n",
        "\n",
        "Ultralytics est la biblioth√®que Python qui nous fournit les outils pour entra√Æner notre mod√®le YOLO.\n",
        "Installons la derni√®re version :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5c0Xuu9qtgl7"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4.1 Choix des param√®tres d'entra√Ænement (√Ä AJUSTER SELON VOS BESOINS)\n",
        "-   `model`: Le mod√®le pr√©-entra√Æn√© qui servira de base. Utiliser un mod√®le pr√©-entra√Æn√© (sur de grands datasets comme COCO) permet un apprentissage plus rapide et efficace (transfer learning).\n",
        "    *   Exemples : `yolo11n.pt` (nano, le plus petit et rapide, id√©al pour commencer), `yolo11s.pt` (small), `yolo11m.pt` (medium), `yolo11l.pt` (large), `yolo11xl.pt` (extra-large, plus pr√©cis mais plus lent et gourmand en ressources).\n",
        "    *   Si vous d√©butez ou avez un petit dataset, `yolo11n.pt` ou `yolo11s.pt` sont de bons choix.\n",
        "    *   Vous pouvez aussi utiliser les mod√®les YOLOv5 et YOLOv8 en changeant `yolo11` par `yolov5` ou `yolov8`.\n",
        "-   `data`: Chemin vers votre fichier `dofus_data.yaml` cr√©√© √† l'√©tape pr√©c√©dente.\n",
        "-   `epochs`: Nombre de fois que le mod√®le verra l'ensemble de votre dataset d'entra√Ænement.\n",
        "    Un bon point de d√©part est entre 25 et 100. Plus de donn√©es ou des t√¢ches plus complexes peuvent n√©cessiter plus d'√©poques. Commencez petit (ex: 30-50) pour un premier test.\n",
        "-   `imgsz` (ou `img`): La taille (r√©solution en pixels) √† laquelle les images seront redimensionn√©es avant d'√™tre pr√©sent√©es au mod√®le.\n",
        "    *   Exemple : `640` (pour des images carr√©es de 640x640). Des tailles plus grandes peuvent am√©liorer la d√©tection de petits objets, mais augmentent l'utilisation de m√©moire GPU (VRAM) et le temps d'entra√Ænement. `320` est aussi une option pour des entra√Ænements plus rapides.\n",
        "-   `batch`: Nombre d'images trait√©es en une seule fois par le GPU.\n",
        "    Une valeur de `-1` laisse Ultralytics choisir automatiquement la meilleure taille de batch en fonction de la VRAM disponible. Sinon, essayez 8, 16, 32...\n",
        "    Si vous avez une erreur \"CUDA out of memory\", r√©duisez cette valeur ou `imgsz`.\n",
        "-   `patience`: Nombre d'√©poques √† attendre sans am√©lioration de la performance sur le set de validation avant d'arr√™ter l'entra√Ænement pr√©matur√©ment (early stopping). Utile pour √©viter le sur-apprentissage. Exemple : `patience=10` (arr√™te si pas d'am√©lioration apr√®s 10 √©poques).\n",
        "\n",
        "Consultez la documentation Ultralytics pour plus d'options : [https://docs.ultralytics.com/modes/train/](https://docs.ultralytics.com/modes/train/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJG1FlWUufOw"
      },
      "outputs": [],
      "source": [
        "# Configuration pour l'entra√Ænement (MODIFIEZ CES VALEURS)\n",
        "MODEL_CHOICE = 'yolo11s.pt'\n",
        "NUM_EPOCHS = 100 # Commencez par un nombre plus petit pour tester (ex: 10-25), puis augmentez.\n",
        "IMAGE_SIZE = 640\n",
        "BATCH_SIZE = -1 # -1 pour auto-batch, ou un nombre comme 8, 16\n",
        "PATIENCE_EPOCHS = 10\n",
        "\n",
        "# Commande d'entra√Ænement\n",
        "!yolo detect train \\\n",
        "    model={MODEL_CHOICE} \\\n",
        "    data={path_to_output_yaml} \\\n",
        "    epochs={NUM_EPOCHS} \\\n",
        "    imgsz={IMAGE_SIZE} \\\n",
        "    batch={BATCH_SIZE} \\\n",
        "    patience={PATIENCE_EPOCHS}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRWN1PD6vMrN"
      },
      "source": [
        "L'entra√Ænement peut prendre un certain temps (de quelques minutes √† plusieurs heures) en fonction de :\n",
        "- La taille de votre dataset.\n",
        "- Le mod√®le (`MODEL_CHOICE`) choisi.\n",
        "- Le nombre d'√©poques (`NUM_EPOCHS`).\n",
        "- La puissance du GPU Colab qui vous est allou√©.\n",
        "\n",
        "\n",
        "**O√π trouver les r√©sultats ?**\n",
        "Les r√©sultats, incluant les poids du mod√®le entra√Æn√© (notamment `best.pt` qui est le plus important), les graphiques de performance, et des exemples de validation, seront sauvegard√©s dans un dossier. Avec les param√®tres ci-dessus, ce sera quelque chose comme :\n",
        "`/content/runs/detect`\n",
        "Vous y trouverez un sous-dossier `weights/` contenant `best.pt` (le mod√®le ayant eu les meilleures performances sur l'ensemble de validation) et `last.pt` (le mod√®le √† la toute derni√®re √©poque)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DEWzef1vPXN"
      },
      "source": [
        "## √âTAPE 5 : TESTER LE MOD√àLE ENTRA√éN√â\n",
        "Une fois l'entra√Ænement termin√©, il est bon de v√©rifier visuellement comment votre mod√®le se comporte sur quelques images qu'il n'a pas vues pendant l'entra√Ænement (celles de votre ensemble de validation).\n",
        "Nous utiliserons le mod√®le `best.pt` car c'est g√©n√©ralement celui qui offre les meilleures performances de g√©n√©ralisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxu_ZGyfvqdU"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vfxjk4XwVa8"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBe5VCwZwpmq"
      },
      "source": [
        "Le mod√®le devrait dessiner des bo√Ætes (bounding boxes) autour des objets d'int√©r√™t qu'il a appris √† reconna√Ætre, avec le nom de la classe et un score de confiance.\n",
        "\n",
        "**Si les r√©sultats ne sont pas satisfaisants :**\n",
        "-   **V√©rifiez vos annotations :** Des erreurs ou incoh√©rences dans l'√©tiquetage (dataset) sont la cause la plus fr√©quente de mauvaises performances.\n",
        "-   **Augmentez le nombre d'√©poques :** Le mod√®le n'a peut-√™tre pas eu assez de temps pour apprendre.\n",
        "-   **Utilisez un mod√®le de base plus grand :** Passez √† `yolo11l.pt` (cela demandera plus de ressources et de temps).\n",
        "-   **Augmentez la taille de votre dataset :** Plus d'images, et surtout plus de diversit√© dans les images (diff√©rents angles, √©clairages, contextes) am√©liorent la robustesse du mod√®le.\n",
        "-   **Data Augmentation :** Ultralytics applique d√©j√† des techniques d'augmentation de donn√©es (rotations, changements de couleurs, etc.) pendant l'entra√Ænement. Vous pouvez explorer des configurations plus avanc√©es si besoin.\n",
        "-   **Ajustez `imgsz` :** Si vos objets sont petits, une r√©solution plus √©lev√©e peut aider.\n",
        "\n",
        "D√©tecter des ressources ici c'est pas mal, mais ce n'est pas tr√®s utile pour r√©colter. On va exporter le mod√®le pour pouvoir l'utiliser en local sur notre ordinateur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ZUARvX9hDk"
      },
      "source": [
        "### VISUALISER LES PERFORMANCES DU MOD√àLE\n",
        "Apr√®s l'entra√Ænement, Ultralytics sauvegarde plusieurs graphiques qui nous aident √† comprendre si notre mod√®le est performant. Nous allons afficher les plus importants et expliquer comment les lire, m√™me sans √™tre un expert en IA !\n",
        "\n",
        "Ces graphiques se trouvent dans le dossier de r√©sultats de votre entra√Ænement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjBqAleM9s44"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from pathlib import Path # Utilis√© pour une recherche plus robuste des dossiers\n",
        "from IPython.display import Image, display, Markdown\n",
        "import textwrap\n",
        "\n",
        "results_base_dir = Path('/content/runs/detect')\n",
        "latest_experiment_path = None # Sera un str\n",
        "\n",
        "if results_base_dir.is_dir():\n",
        "    # Obtenir tous les sous-dossiers commen√ßant par 'train'\n",
        "    experiment_dirs = [d for d in results_base_dir.glob('train*') if d.is_dir()]\n",
        "\n",
        "    if experiment_dirs:\n",
        "        # Trouver celui avec le temps de modification le plus r√©cent\n",
        "        # Cela correspond g√©n√©ralement au dernier entra√Ænement effectu√©.\n",
        "        latest_experiment_path_obj = max(experiment_dirs, key=lambda p: p.stat().st_mtime)\n",
        "        latest_experiment_path = str(latest_experiment_path_obj) # Convertir Path en string\n",
        "        print(f\"Analyse des r√©sultats depuis : {latest_experiment_path}\\n\")\n",
        "    else:\n",
        "        print(f\"Aucun sous-dossier 'train*' trouv√© dans '{results_base_dir}'.\")\n",
        "        print(\"Veuillez vous assurer que l'√âtape 4 (Entra√Ænement) a bien √©t√© ex√©cut√©e.\")\n",
        "else:\n",
        "    print(f\"Le dossier de base des r√©sultats '{results_base_dir}' n'existe pas.\")\n",
        "    print(\"Veuillez vous assurer que l'√âtape 4 (Entra√Ænement) a bien √©t√© ex√©cut√©e.\")\n",
        "\n",
        "\n",
        "# --- Suite du code de visualisation, seulement si latest_experiment_path a √©t√© trouv√© ---\n",
        "if latest_experiment_path and os.path.isdir(latest_experiment_path):\n",
        "\n",
        "    # --- 1. Affichage du graphique principal des r√©sultats (results.png) ---\n",
        "    results_png_path = None # Initialisation\n",
        "    # Chercher les fichiers PNG pertinents pour les m√©triques\n",
        "    possible_results_plots = ['results.png', 'metrics_plot.png', 'P_R_F1_curve.png', 'F1_curve.png', 'PR_curve.png']\n",
        "    found_results_plot = False\n",
        "    for plot_name in possible_results_plots:\n",
        "        potential_path = os.path.join(latest_experiment_path, plot_name)\n",
        "        if os.path.exists(potential_path):\n",
        "            results_png_path = potential_path\n",
        "            found_results_plot = True\n",
        "            print(f\"Graphique des m√©triques principales trouv√© : {results_png_path}\")\n",
        "            break\n",
        "\n",
        "    if found_results_plot and results_png_path:\n",
        "        display(Markdown(\"### 1. Graphique des M√©triques d'Entra√Ænement et de Validation\"))\n",
        "        display(Image(filename=results_png_path, width=800)) # Ajustez width si besoin\n",
        "\n",
        "        explanation_markdown = textwrap.dedent(\"\"\"\n",
        "        **Comment lire ce graphique ?**\n",
        "\n",
        "        *   **Axe X (Horizontal - Epochs) :** Repr√©sente les cycles d'entra√Ænement. Plus on va vers la droite, plus le mod√®le a √©t√© entra√Æn√© longtemps.\n",
        "        *   **Axe Y (Vertical) :** Repr√©sente la valeur de la m√©trique (g√©n√©ralement entre 0 et 1, o√π 1 est parfait).\n",
        "\n",
        "        **Les courbes importantes √† regarder :**\n",
        "        (Les noms exacts des courbes peuvent l√©g√®rement varier, mais cherchez des termes similaires)\n",
        "\n",
        "        *   **`metrics/precision` (ou P) : Pr√©cision.**\n",
        "            *   **Ce que √ßa veut dire :** Quand le mod√®le dit \"J'ai trouv√© un objet X\", quelle est la probabilit√© qu'il ait raison ?\n",
        "            *   **Ce qu'on veut :** Une courbe qui monte et se stabilise le plus haut possible (proche de 1).\n",
        "        *   **`metrics/recall` (ou R) : Rappel (ou Sensibilit√©).**\n",
        "            *   **Ce que √ßa veut dire :** Parmi tous les objets X r√©ellement pr√©sents dans les images, combien le mod√®le a-t-il r√©ussi √† trouver ?\n",
        "            *   **Ce qu'on veut :** Une courbe qui monte et se stabilise le plus haut possible (proche de 1).\n",
        "        *   **`metrics/mAP50` (ou `mAP@.50`) : Mean Average Precision √† IoU=0.5.**\n",
        "            *   **Ce que √ßa veut dire :** C'est une sorte de **score global de performance**. Il combine la pr√©cision et le rappel pour toutes les classes, et consid√®re une d√©tection comme correcte si la bo√Æte pr√©dite chevauche la vraie bo√Æte d'au moins 50% (c'est le \"IoU=0.5\").\n",
        "            *   **Ce qu'on veut :** Une courbe qui monte et se stabilise le plus haut possible (proche de 1). C'est souvent la m√©trique principale pour juger la qualit√© globale.\n",
        "        *   **`metrics/mAP50-95` (ou `mAP@.50:.95`) : mAP moyenn√©e sur plusieurs seuils d'IoU (de 0.5 √† 0.95).**\n",
        "            *   **Ce que √ßa veut dire :** Similaire √† `mAP50`, mais plus strict car il exige un meilleur placement des bo√Ætes sur une plage de seuils.\n",
        "            *   **Ce qu'on veut :** Une courbe qui monte. Elle sera g√©n√©ralement plus basse que `mAP50`.\n",
        "\n",
        "        **Courbes `train/...` vs `val/...` :**\n",
        "        *   Les courbes avec `train` (ex: `train/box_loss`) montrent comment le mod√®le performe sur les donn√©es qu'il *voit* pendant l'entra√Ænement.\n",
        "        *   Les courbes avec `val` (ex: `val/box_loss` ou directement les m√©triques comme `metrics/mAP50` qui sont calcul√©es sur le set de validation) montrent comment le mod√®le performe sur des donn√©es *nouvelles* qu'il n'a jamais vues. C'est **CRUCIAL** pour voir si le mod√®le g√©n√©ralise bien ou s'il \"apprend par c≈ìur\" (sur-apprentissage).\n",
        "        *   Id√©alement, les courbes `train` et `val` pour les m√©triques (P, R, mAP) doivent √™tre proches et monter ensemble. Si les performances sur `train` sont excellentes mais celles sur `val` sont bien moins bonnes et stagnent ou baissent, c'est un signe de sur-apprentissage.\n",
        "\n",
        "        **En r√©sum√© pour un non-expert :** Recherchez les courbes de **Pr√©cision, Rappel, et mAP50 (ou mAP@0.5)**. Si elles montent et atteignent des valeurs √©lev√©es (disons, > 0.7 ou 0.8 pour un bon mod√®le, mais cela d√©pend de la difficult√© de la t√¢che), c'est un bon signe ! Si elles stagnent bas, le mod√®le n'apprend pas bien.\n",
        "        \"\"\")\n",
        "        display(Markdown(explanation_markdown))\n",
        "    else:\n",
        "        print(\"Le graphique principal des r√©sultats (`results.png` ou similaire) n'a pas √©t√© trouv√© dans le dossier d'exp√©rience.\")\n",
        "\n",
        "    # --- 2. Affichage de la Matrice de Confusion (confusion_matrix.png) ---\n",
        "    confusion_matrix_png_path = os.path.join(latest_experiment_path, 'confusion_matrix.png')\n",
        "    if os.path.exists(confusion_matrix_png_path):\n",
        "        display(Markdown(\"### 2. Matrice de Confusion\"))\n",
        "        display(Image(filename=confusion_matrix_png_path, width=600)) # Ajustez width si besoin\n",
        "\n",
        "        # Essayer de charger classes.txt pour rendre la matrice de confusion plus lisible\n",
        "        classes_txt_path = '/content/custom_data/classes.txt' # Chemin vers le fichier classes.txt original\n",
        "        class_names = []\n",
        "        if os.path.exists(classes_txt_path):\n",
        "            with open(classes_txt_path, 'r') as f:\n",
        "                class_names = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        explanation_text_cm = textwrap.dedent(\"\"\"\n",
        "        **Comment lire cette matrice ?**\n",
        "\n",
        "        Cette matrice vous montre quelles classes le mod√®le a tendance √† confondre entre elles.\n",
        "        *   **Lignes :** Les vraies classes des objets (V√©rit√© Terrain).\n",
        "        *   **Colonnes :** Les classes pr√©dites par le mod√®le.\n",
        "        *   **Diagonale (du haut-gauche au bas-droite) :** Les pr√©dictions correctes. Plus les chiffres (et les couleurs plus intenses) sont sur la diagonale, mieux c'est !\n",
        "        *   **Cases hors diagonale :** Les erreurs de classification. Par exemple, si dans la ligne \"Frene\" et la colonne \"Ble\", il y a un chiffre, cela signifie que le mod√®le a parfois confondu un \"Frene\" avec un \"Ble\".\n",
        "        *   **Derni√®re ligne/colonne (`background`) :**\n",
        "            *   `background` en ligne : Indique les objets r√©els qu'aucune bo√Æte n'a d√©tect√©s (faux n√©gatifs pour cette classe).\n",
        "            *   `background` en colonne : Indique les bo√Ætes pr√©dites qui ne correspondaient √† aucun objet r√©el (faux positifs).\n",
        "\n",
        "        **Ce qu'on veut :**\n",
        "        *   Des valeurs √©lev√©es et des couleurs vives sur la **diagonale principale**.\n",
        "        *   Des valeurs faibles (proches de 0) et des couleurs claires **partout ailleurs**.\n",
        "        *   Des valeurs faibles dans la derni√®re ligne/colonne \"background\" (sauf pour la case background/background si elle existe).\n",
        "        \"\"\")\n",
        "        if class_names:\n",
        "            # Concat√©nation de cha√Ænes, textwrap.dedent n'est pas n√©cessaire ici car les f-strings g√®rent bien\n",
        "            class_list_md = \"\\n**Vos classes sont (dans l'ordre de la matrice, en commen√ßant par 0) :**\\n\"\n",
        "            for i, name in enumerate(class_names):\n",
        "                class_list_md += f\"  {i}: {name}\\n\"\n",
        "            explanation_text_cm += class_list_md # Ajouter la liste des classes √† la fin\n",
        "\n",
        "        display(Markdown(explanation_text_cm))\n",
        "\n",
        "    else:\n",
        "        print(f\"La matrice de confusion (`confusion_matrix.png`) n'a pas √©t√© trouv√©e dans {latest_experiment_path}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n1ZSgbJxjwX"
      },
      "source": [
        "## √âTAPE 6 : PR√âPARER ET T√âL√âCHARGER VOTRE MOD√àLE ENTRA√éN√â\n",
        "Nous allons maintenant cr√©er un package ZIP contenant :\n",
        "1.  Votre meilleur mod√®le entra√Æn√© (`best.pt` renomm√© en `my_model.pt`).\n",
        "2.  (Optionnel) Le dossier complet des r√©sultats de l'entra√Ænement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOkHYydFyLNI"
      },
      "outputs": [],
      "source": [
        "# Cr√©er un fichier \"dofus_AI\" pour y mettre les poids et les r√©sultats d'entrainements\n",
        "!mkdir /content/dofus_AI\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/dofus_AI/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/dofus_AI\n",
        "\n",
        "# cr√©er le zip \"dofus_AI.zip\"\n",
        "%cd dofus_AI\n",
        "!zip /content/dofus_AI.zip my_model.pt\n",
        "!zip -r /content/dofus_AI.zip train\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyxotKfVzHk9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/dofus_AI.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48XRUBwc8AgS"
      },
      "source": [
        "Une fois le t√©l√©chargement termin√©, vous aurez `dofus_AI.zip` sur votre ordinateur. Ce ZIP contient tout ce dont vous avez besoin pour r√©utiliser votre mod√®le ou analyser plus en d√©tail l'entra√Ænement.\n",
        "\n",
        "**F√©licitations !** Vous avez entra√Æn√© et packag√© votre propre mod√®le de d√©tection d'objets pour Dofus."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
